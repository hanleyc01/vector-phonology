# vector-phonology

- Generative phonology posits that, in language acquisition, we come to form underlying representations of words through repeatedly hearing speech sounds in use, composed of cognitive units called *phonemes*
 - We come to form phonemes by *overgeneralizing similarity* relations between the physical characteristics of sounds and their distributions in use
 - Generative phonology posits that these phonemes are distinguished by, and operate in, the domain of distinctive segmental features. But, it does not make a claim as to how these features come to be known, nor does it make a claim about why they are so arranged, aside from broad structrual differences in their phonetic realization.
 - Thus, the goal of this project is to come to an understanding, in some sense, over what makes motivates distinctive phonological features by modelling the process of language acquisition with Nengo spiking neurons
     + Nengo Spiking neurons are a model of actual neuronal relations in the brain
 - Our hypothesis is that, given the success of generative phonological methods, the neural network will generate *something like distinctive features*, motivated for structural differences in phonetic realization, and further, the need to group together different sounds so as to make computation more effective.
     + In other words, we posit that there is a computational constraint on computation and cognition of language, given that the physical phenomena of speech acts are so varied between speakers, such that grouping together structrually similar sounds into phonemes is motivated. Further, that these phonemes will be distinguished by something like distinctive segmental features, which are abstractions from articulation

[Here is a link to NengoSPA](https://www.nengo.ai/nengo-spa/v1.3.0/index.html)
